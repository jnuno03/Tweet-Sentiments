# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]

# C extensions
*.so

# Distribution / packaging
.Python
env/
bin/
build/
develop-eggs/
dist/
eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.cache
nosetests.xml
coverage.xml

# Translations
*.mo

# Mr Developer
.mr.developer.cfg
.project
.pydevproject

# Rope
.ropeproject

# Django stuff:
*.log
*.pot

# Sphinx documentation
docs/_build/


def main():

    # ask user for input
    all_tweets = make_tweets(raw_input('Please enter tweet file name (filename.txt): '))
    all_zips = make_zip_list(raw_input('Please enter zipcode file name (filename.csv): '))
    all_sentiments = make_sentiments_list(raw_input('Please enter sentiments file name (filename.csv): '))
    outfile = raw_input('Please enter out file name (filename.txt):')

    # add zip, state, and sentiment to tweet dictionaries
    new_dicts = add_geo(all_tweets, all_zips)


    # ask the user about filtering
    state = raw_input("Do you want to filter by state? (y=1/n=0)")
    zipcode = raw_input("Do you want to filter by zipcode? (y=1/n=0)")
    word = raw_input("Do you want to filter by word? (y=1/n=0)")

    # if the user wants to filter, ask for more specifics
    if state == '1':
        st = raw_input("What state do you want to filter by? (abbrevation, please)")
        new_dicts = tweet_filter(new_dicts, state=st)
    
    if zipcode == '1':
        zp = raw_input("What zipcode do you want to filter by?")
        new_dicts = tweet_filter(new_dicts, zipcode=zp)

    if word == '1':
        wrd = raw_input("What word do you want to filter by?")
        new_dicts = tweet_filter(new_dicts, word=wrd)

    

    rewritten_tweets = add_sentiment(new_dicts, all_sentiments)
    average = average_filtered_sent(new_dicts)
        
    # write dictionaries in txt file
    final_tweets = write_tweets(rewritten_tweets, outfile)

    # print average of the tweets
    print average

    
def make_sentiment(sentiment):
    """Return a sentiment as a python dictionary
    sentiment_file: a list containining a single
    sentiment's data ordered as in zips.csv"""
    return {"sentiment":str(sentiment[0]), "value":float(sentiment[1])}

def make_sentiments_list(sentiment_file):
    """Takes in a csv file of sentiments and
    returns a list of dictionarys for each word"""
    all_sentiments = open(sentiment_file, 'rU')
    reader = csv.reader(all_sentiments)
    sentiments_list = []
    # reads each line in csv file
    for line in reader:
        # appends dictionaries to a list for each line in csv file
        sentiments_list.append(make_sentiment(line))
    return sentiments_list

def find_tweet_sentiment(tweet, sentiment_list):
    """Returns the mean sentiment of the tweet"""
    sentiment_total = 0
    word_count = 0
    tweet_word = tweet_words(tweet)
    for word in tweet_word:
        # look in the sentiments list for the word in the list
        for sentiment in sentiment_list:
            # if the word is equal to the sentiment we add the value
            if word == sentiment['sentiment']:
                sentiment_total += sentiment['value']
                word_count = word_count + 1
        
    # if the word was not in the file we return None
    if word_count == 0:
        return None
    else: 
        return sentiment_total/word_count
        
def add_sentiment(tweets, sentiment_list):
    """Return an updated dictionary with the keyword sentiment
    tweets: list of dictionaries
    sentiments_list: a list of sentiment dictionaries"""
    # add sentiment key to dictionary
    for tweet in tweets:
        tweet['sentiment'] = find_tweet_sentiment(tweet, sentiment_list)
    return tweets

def tweet_filter(tweets, **kwargs):
    """takes in tweets (a list of dictionaries) and keyword
    arguments. returns the filtered list"""
    filtered_list = []

    # calls the filter functions depending on keyword arguments
    if kwargs is not None:
        if 'word' in kwargs:
            filtered_list = filter_by_word(tweets, **kwargs) 
        if 'zipcode' in kwargs:
            filtered_list = filter_by_zip(tweets, **kwargs)
        if 'state' in kwargs:
            filtered_list = filter_by_state(tweets, **kwargs)
                    
        return filtered_list
    else:
        return tweets

def filter_by_word(tweets, **kwargs):
    """Returns list filtered by word"""
    filtered_list = []

    for tweet in tweets:
        found = False
        # returns a list of words in tweet with no punctuation
        word_list = tweet_words(tweet)
        # iterate through list
        for single_word in word_list:
            # boolean makes sure tweets arent written multiple times
            if single_word == kwargs['word'] and found == False:
                filtered_list.append(tweet)
                found = True
    return filtered_list

def filter_by_zip(tweets, **kwargs):
    """Returns list filtered by zip"""
    filtered_list = []
    if len(tweets) != 0:
        for tweet in tweets:
            if kwargs['zipcode'] == tweet['zip']:
                filtered_list.append(tweet)
    return filtered_list

def filter_by_state(tweets, **kwargs):
    """returns list filtered by state"""
    filtered_list = []
    for tweet in tweets:
        if kwargs['state'] == tweet['state'].replace('"','').strip():
            filtered_list.append(tweet)
    return filtered_list

def average_filtered_sent(filtered_tweets):
    """Returns the average sentiment of the filtered tweets"""
    tweet_count = 0
    total_sent = 0
    for tweet in filtered_tweets:
        if tweet['sentiment'] is not None:
            total_sent = total_sent + float(tweet['sentiment'])
        tweet_count = tweet_count + 1
    return total_sent/tweet_count






# Phase 1: Adding geo data

import csv
import datetime
import math
import string


def make_tweets(tweet_file):
    """Returns a list of dictionaries"""
    infile = open(tweet_file, 'r')
    tweets = []
    first_line = infile.readline()
    for line in infile:
        tweets.append(make_tweet(line))
    return tweets

def make_tweet(tweet_line):
    """Return a tweet, represented as a python dictionary.
    tweet_line: a string corresponding to a line formatted as in all_tweets.txt

    Dictionary keys:
    text  -- A string; the text of the tweet, all in lowercase
    time  -- A datetime object; the time that the tweet was posted
    lat   -- A number; the latitude of the tweet's location
    lon   -- A number; the longitude of the tweet's location

    """
  

    
    # split the line
    split = tweet_line.split("\t")
    
    # retrieve and split lat and long
    split_lat_lon = split[0].split()
    
    # strip ends
    lat = split_lat_lon[0].rstrip(',').lstrip('[')
    lon = split_lat_lon[1].rstrip(']').lstrip(' ')

    # retrieve and split date and time
    date_time = split[2].split()

    date = date_time[0].split('-')
    year = date[0]
    month = date[1]
    day = date[2]

    time = date_time[1].split(":")
    hour = time[0]
    minute = time[1]
    second = time[2]

    d = datetime.datetime(int(year),int(month),int(day),int(hour),int(minute),int(second))

    tweet = {"text": split[3].lower().strip(), "time": d, "lat": float(lat), "lon": float(lon)}
    return tweet

def tweet_text(tweet):
    """Return the text of a tweet as a string"""
    return tweet["text"]

def tweet_words(tweet):
    """Return a list of the words in the text of a tweet not
    including punctuation."""
    
    split = tweet_text(tweet).split()
    tweet_word = []
    for word in split:
        for character in word:
            for j in string.punctuation:
                if character == j:
                    word.strip(j)
            tweet_word.append(word)
    return tweet_word

def tweet_time(tweet):
    """Return the datetime that represents when the tweet was posted."""
    
    return tweet["time"]

def tweet_location(tweet):
    """Return an tuple that represents the tweet's location."""
   
    return (tweet["lat"], tweet["lon"])

def make_zip_list(csv_file):
    """Returns a list of dictionaries"""
    all_zip_codes = open(csv_file, 'rU')
    reader = csv.reader(all_zip_codes)
    zip_list = []
    line = reader.next()
    for line in reader:
        zip_list.append(make_zip(line))
    return zip_list
    
def make_zip(zipcode):
    """Return a zip code, represented as a python dictionary.
    zipcode: a list containing a single zip codes data ordered as in zips.csv

    Dictionary keys:
    zip    -- A string; the sip code
    state   -- A string; Two-letter postal code for state
    lat    -- A number; latitude of zip code location
    lon    -- A number; longitude of zip code location
    city   -- A string; name of city assoicated with zip code

    """

    return {"zip":str(zipcode[0]), "state":zipcode[1], "lat":float(zipcode[2].replace('"',"").strip()), "lon":float(zipcode[3].replace('"',"").strip()), "city":zipcode[4]}

def find_zip(tweet, zip_list):
    """return zipcode associated with a tweets location data
    zip_list is a list of zip_codes represented as dictionaries"""
    lat_lon = tweet_location(tweet)
    distance = geo_distance(lat_lon, (zip_list[0]["lat"],zip_list[0]["lon"]))

    for index in range(1, len(zip_list)):
        if distance > geo_distance(lat_lon, (zip_list[index]["lat"], zip_list[index]["lon"])):
            distance = geo_distance(lat_lon, (zip_list[index]["lat"], zip_list[index]["lon"]))
            location = index
    return zip_list[location]["zip"]
    

def find_state(tweet, zip_list):
    """Returns the state of a tweet"""
    lat_lon = tweet_location(tweet)
    distance = geo_distance(lat_lon, (zip_list[0]['lat'],zip_list[0]['lat']))

    for index in range(1, len(zip_list)):
        if distance > geo_distance(lat_lon, (zip_list[index]['lat'],zip_list[index]['lat'])):
            distance = geo_distance(lat_lon, (zip_list[index]['lat'],zip_list[index]['lat']))
            location = index
    return zip_list[location]["state"]

def geo_distance(loc1,loc2):
    """Return the great circle distance (in miles) between two
    tuples of (latitude,longitude)

    Uses the "haversine" formula.
    http://en.wikipedia.org/wiki/Haversine_formula"""
    p1 = math.radians(loc1[0])
    p2 = math.radians(loc2[0])
    l1 = math.radians(loc1[1])
    l2 = math.radians(loc2[1])
    r = 3959 # miles
    d = 2*r*math.asin(math.sqrt((math.sin((p2-p1)/2))**2 + math.cos(p1)*math.cos(p2)*(math.sin((l2-l1)/2))**2))
    return d

def add_geo(tweets, zip_list):
    """adds the new keys state and zip to each tweet dictionary in the list tweets"""
    for tweet in tweets:
        tweet['zip'] = find_zip(tweet, zip_list)
        tweet['state'] = find_state(tweet, zip_list)
    return tweets      

def write_tweets(tweets,outfile):
    """writes the list of tweets to a text file with name outfile"""
    out_file = open(outfile, 'w')
    for item in tweets:
        out_file.write(str(item['lat']))
        out_file.write('\t')
        out_file.write(str(item['lon']))
        out_file.write('\t')
        out_file.write(str(item['time']))
        out_file.write('\t')
        out_file.write(str(item['text']))
        out_file.write('\t')
        out_file.write(str(item['state'].replace('"',"")))
        out_file.write('\t')
        out_file.write(str(item['zip']))
        out_file.write('\t')
        out_file.write(str(item['sentiment']))
        out_file.write('\n')
    out_file.close()
    return out_file
                        

main()

